{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Zero-Shot Classification\n",
    "\n",
    "In this notebook, we'll use the `zero-shot-classification` pipeline from the HF Transformers library to predict the intents of sentences in a dataset. We'll compare the predicted intents with the actual labels and print the evaluation metrics.\n",
    "\n",
    "Creating an NLP-based framework to parse the input question to categorize the intent into one of the question types.\n",
    "\n",
    "Question Types:\n",
    "1. Why is action A not used in the plan, rather than being used?\n",
    "2. Why is action A used in the plan, rather than not being used?\n",
    "3. Why is action A used in state S, rather than action B?"
   ],
   "id": "65af76665474c488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single Text Prediction",
   "id": "3996a58d6e7648eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:24:09.764861Z",
     "start_time": "2024-06-03T01:24:07.392205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from pprint import pprint"
   ],
   "id": "f985e2baedd364d2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:24:13.481780Z",
     "start_time": "2024-06-03T01:24:09.765715Z"
    }
   },
   "source": [
    "# Load a pre-trained zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:24:15.452639Z",
     "start_time": "2024-06-03T01:24:13.482860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the query and candidate labels\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used in state S, rather than action B?\"]\n",
    "query = \"What made 'push box to the left' more suitable than 'move to the right'?\"\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(query, candidate_labels)\n",
    "pprint(result, width=100)"
   ],
   "id": "11ca92d38e459308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Why is action A used in the plan?',\n",
      "            'Why is action A not used in the plan?',\n",
      "            'Why is action A used in state S, rather than action B?'],\n",
      " 'scores': [0.3973885476589203, 0.3694774806499481, 0.2331339716911316],\n",
      " 'sequence': \"What made 'push box to the left' more suitable than 'move to the right'?\"}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:24:17.616969Z",
     "start_time": "2024-06-03T01:24:15.454480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the query and candidate labels\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used rather than action B?\"]\n",
    "query = \"What made 'push box to the left' more suitable than 'move to the right'?\"\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(query, candidate_labels)\n",
    "pprint(result, width=100)"
   ],
   "id": "7c4f14fc6d35d73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Why is action A used rather than action B?',\n",
      "            'Why is action A used in the plan?',\n",
      "            'Why is action A not used in the plan?'],\n",
      " 'scores': [0.7602096199989319, 0.12425892055034637, 0.11553144454956055],\n",
      " 'sequence': \"What made 'push box to the left' more suitable than 'move to the right'?\"}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It seems that \"Why is action A used rather than action B?\" is a better intent category label than \"Why is action A used in state S, rather than action B?\".",
   "id": "792b0f39e6f149da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<br>",
   "id": "e4973a09e9b1342d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Prediction using Base Model\n",
    "Predict the intents of the sentences in the text column from the data csv, compare them with the actual labels, and print the evaluation metrics.\n",
    "\n",
    "Use the base model."
   ],
   "id": "9da3c2e820168eb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:53:48.037720Z",
     "start_time": "2024-06-03T01:53:48.033872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import swifter\n",
    "import wandb\n",
    "import os"
   ],
   "id": "eeeacfb419714fb6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:54:25.456006Z",
     "start_time": "2024-06-03T01:54:25.449110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"] = \"zero-shot-classification\"\n",
    "\n",
    "# save your trained model checkpoint to wandb\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\""
   ],
   "id": "95c8aea6223cf625",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:55:56.125445Z",
     "start_time": "2024-06-03T01:55:56.052418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('./data/combined_dataset.csv')\n",
    "print(f\"Number of rows in the dataset: {df.shape[0]}\")\n",
    "df.head()"
   ],
   "id": "f63211774ea13f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0           Why was action A excluded from the plan?      1\n",
       "1  What were the reasons for omitting action A fr...      1\n",
       "2  Can you explain why action A was not considere...      1\n",
       "3              Why didn't the plan include action A?      1\n",
       "4  What is the rationale for not using action A i...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why was action A excluded from the plan?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What were the reasons for omitting action A fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you explain why action A was not considere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why didn't the plan include action A?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the rationale for not using action A i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:56:01.903743Z",
     "start_time": "2024-06-03T01:56:01.898107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the candidate labels and their corresponding intent numbers\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used rather than action B?\"]\n",
    "\n",
    "intent_to_label = {label: intent for label, intent in zip(candidate_labels, range(1, 4))}\n",
    "intent_to_label"
   ],
   "id": "e4aea201d3bdc9ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Why is action A not used in the plan?': 1,\n",
       " 'Why is action A used in the plan?': 2,\n",
       " 'Why is action A used rather than action B?': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:56:08.319812Z",
     "start_time": "2024-06-03T01:56:04.257631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load a pre-trained zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Function to get predictions for each text\n",
    "def get_prediction(text):\n",
    "    result = classifier(text, candidate_labels)\n",
    "    predicted_label = intent_to_label[result['labels'][0]]\n",
    "    return predicted_label"
   ],
   "id": "70fc8d178444a138",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:08:53.570342Z",
     "start_time": "2024-06-03T01:56:08.861162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to the text column\n",
    "df['predicted_label'] = df['text'].swifter.apply(get_prediction)"
   ],
   "id": "9a858916c12682b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/346 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d40e9a50c21c4e8cbe32aa1211f95d0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:08:53.587383Z",
     "start_time": "2024-06-03T02:08:53.572884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare predicted labels with actual labels\n",
    "y_true = df['label']\n",
    "y_pred = df['predicted_label']\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")"
   ],
   "id": "a5c48f13821b6de4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.97      0.84       116\n",
      "           2       0.98      0.94      0.96       115\n",
      "           3       0.90      0.65      0.76       115\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.87      0.86      0.85       346\n",
      "weighted avg       0.87      0.86      0.85       346\n",
      "\n",
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:08:53.600333Z",
     "start_time": "2024-06-03T02:08:53.588417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the rows in which the predictions didn't match the label\n",
    "incorrect_predictions = df[df['label'] != df['predicted_label']]\n",
    "print(f\"{incorrect_predictions.shape[0]} incorrect predictions out of {df.shape[0]} test samples.\")\n",
    "incorrect_predictions.head()"
   ],
   "id": "51ca88d65c800c3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 incorrect predictions out of 346 test samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                  text  label  predicted_label\n",
       "46   The player doesn't push any boxes. Shouldn't p...      1                2\n",
       "96   What's the justification for not using 'move r...      1                3\n",
       "102     What is the reasoning for not using 'push up'?      1                3\n",
       "176  What made the plan opt for 'move left' instead...      2                1\n",
       "186  What was the reasoning for 'move down' being s...      2                3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The player doesn't push any boxes. Shouldn't p...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What's the justification for not using 'move r...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>What is the reasoning for not using 'push up'?</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>What made the plan opt for 'move left' instead...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>What was the reasoning for 'move down' being s...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Prediction using Fine-Tuned Model",
   "id": "ee1d2c07765960c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:10:11.224593Z",
     "start_time": "2024-06-03T02:10:11.183531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from numpy import argmax\n",
    "from utils import get_best_available_device"
   ],
   "id": "554b8067fd516e43",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:10:11.970894Z",
     "start_time": "2024-06-03T02:10:11.921383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = get_best_available_device()\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "cb32e83bf1d8f586",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:10:16.283835Z",
     "start_time": "2024-06-03T02:10:16.265219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CSV has columns 'text' and 'label'\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=13)\n",
    "\n",
    "# Convert to Hugging Face Datasets format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ],
   "id": "b03da143a1a75faa",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:12:49.918222Z",
     "start_time": "2024-06-03T02:12:49.627273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use a tokenizer to preprocess the text data:\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ],
   "id": "a756f34d93f71df9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/276 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7422c6d945ce4eb9a3bcee41299dbd12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab983d9794074503a0b22764f61161fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:12:57.552854Z",
     "start_time": "2024-06-03T02:12:51.633006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.to(device);"
   ],
   "id": "312fe8455acf8b59",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:12:57.560577Z",
     "start_time": "2024-06-03T02:12:57.555255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pass \"wandb\" to the 'report_to' parameter to turn on wandb logging\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to=\"wandb\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "id": "2bcf8263e3f11576",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:12:57.565628Z",
     "start_time": "2024-06-03T02:12:57.561891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the metrics to evaluate the model\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = argmax(pred, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted')\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ],
   "id": "2d06efc07122d4f0",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:17:04.967976Z",
     "start_time": "2024-06-03T02:13:36.393600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "702523e8f2b4ad8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/54 01:31 < 1:17:59, 0.01 it/s, Epoch 0.11/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      3\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[1;32m      7\u001B[0m )\n\u001B[0;32m----> 9\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/transformers/trainer.py:1885\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1883\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1884\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1885\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   1886\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   1887\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   1888\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   1889\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   1890\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/transformers/trainer.py:2279\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2276\u001B[0m         grad_norm \u001B[38;5;241m=\u001B[39m _grad_norm\n\u001B[1;32m   2278\u001B[0m \u001B[38;5;66;03m# Optimizer step\u001B[39;00m\n\u001B[0;32m-> 2279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m   2280\u001B[0m optimizer_was_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39moptimizer_step_was_skipped\n\u001B[1;32m   2281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer_was_run:\n\u001B[1;32m   2282\u001B[0m     \u001B[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/accelerate/optimizer.py:170\u001B[0m, in \u001B[0;36mAcceleratedOptimizer.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerate_step_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 170\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep(closure)\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator_state\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mXLA:\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_state\u001B[38;5;241m.\u001B[39mis_xla_gradients_synced \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     74\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/adamw.py:187\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    174\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    176\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    177\u001B[0m         group,\n\u001B[1;32m    178\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m         state_steps,\n\u001B[1;32m    185\u001B[0m     )\n\u001B[0;32m--> 187\u001B[0m     adamw(\n\u001B[1;32m    188\u001B[0m         params_with_grad,\n\u001B[1;32m    189\u001B[0m         grads,\n\u001B[1;32m    190\u001B[0m         exp_avgs,\n\u001B[1;32m    191\u001B[0m         exp_avg_sqs,\n\u001B[1;32m    192\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    193\u001B[0m         state_steps,\n\u001B[1;32m    194\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    195\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    196\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    197\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    198\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    199\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    200\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    201\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    202\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    203\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    204\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    205\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    206\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    207\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    208\u001B[0m     )\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/adamw.py:339\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    337\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 339\u001B[0m func(\n\u001B[1;32m    340\u001B[0m     params,\n\u001B[1;32m    341\u001B[0m     grads,\n\u001B[1;32m    342\u001B[0m     exp_avgs,\n\u001B[1;32m    343\u001B[0m     exp_avg_sqs,\n\u001B[1;32m    344\u001B[0m     max_exp_avg_sqs,\n\u001B[1;32m    345\u001B[0m     state_steps,\n\u001B[1;32m    346\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    347\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    348\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    349\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m    350\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[1;32m    351\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m    352\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[1;32m    353\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m    354\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[1;32m    355\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[1;32m    356\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[1;32m    357\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    358\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/auto-plan/lib/python3.11/site-packages/torch/optim/adamw.py:415\u001B[0m, in \u001B[0;36m_single_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[1;32m    412\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;66;03m# Perform stepweight decay\u001B[39;00m\n\u001B[0;32m--> 415\u001B[0m param\u001B[38;5;241m.\u001B[39mmul_(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m lr \u001B[38;5;241m*\u001B[39m weight_decay)\n\u001B[1;32m    417\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    418\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T02:18:03.097237Z",
     "start_time": "2024-06-03T02:17:55.869479Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "50847f23e73e8aee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d043a27be6b343389510a51e9613f809"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">./results</strong> at: <a href='https://wandb.ai/niting/zero-shot-classification/runs/ccawbr7t' target=\"_blank\">https://wandb.ai/niting/zero-shot-classification/runs/ccawbr7t</a><br/> View project at: <a href='https://wandb.ai/niting/zero-shot-classification' target=\"_blank\">https://wandb.ai/niting/zero-shot-classification</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240602_221057-ccawbr7t/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "id": "a1eb2e3e2db28a52",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
