# Contrastive Planning

This project tackles the challenge of transparency in automated planning. When a proposed plan deviates from user expectations, explanations are crucial. We tackle this need by introducing a novel framework designed to generate contrastive explanations for plans specifically within the Sokoban domain. This framework leverages the strengths of Planning Ontology and integrates Natural Language Processing (NLP) with SPARQL queries to provide clear and insightful explanations. At the heart of this framework lies a dedicated knowledge graph (KG) which allows the system to possess a deeper understanding of the planning world. Its enriched ontology empowers the system to comprehend user queries about specific actions and their significance within a plan. An NLP module plays a critical role, acting as a bridge between natural language and the formal representation within KG. By categorizing user queries into planned actions, the NLP module facilitates the retrieval process. The query type, such as "why action A is not used" or "why action A is preferred over action B," dictates the system's retrieval process. It extracts relevant information from the KG, considering the enriched ontology, and formulates explanations dynamically. This empowers the system to explain why specific actions were included, excluded, or prioritized over others, fostering a deeper understanding of the automated planning process. This research contributes to the field of Explainable AI by fostering a deeper understanding of automated planning systems and their decision-making processes. The project not only advances user trust in automated planning systems by providing explanations for actions within plans, but it also has the potential to be extended beyond Sokoban. This framework serves as a foundation for generating explanations in other planning domains such as Rubikâ€™s Cube, N-Puzzle, and FreeCell.