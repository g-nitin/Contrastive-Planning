{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Zero-Shot Classification\n",
    "\n",
    "In this notebook, we'll use the `zero-shot-classification` pipeline from the HF Transformers library to predict the intents of sentences in a dataset. We'll compare the predicted intents with the actual labels and print the evaluation metrics.\n",
    "\n",
    "Creating an NLP-based framework to parse the input question to categorize the intent into one of the question types.\n",
    "\n",
    "Question Types:\n",
    "1. Why is action A not used in the plan, rather than being used?\n",
    "2. Why is action A used in the plan, rather than not being used?\n",
    "3. Why is action A used in state S, rather than action B?"
   ],
   "id": "65af76665474c488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single Text Prediction",
   "id": "3996a58d6e7648eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:14.753373Z",
     "start_time": "2024-05-31T02:26:14.751024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from pprint import pprint"
   ],
   "id": "f985e2baedd364d2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:19.730553Z",
     "start_time": "2024-05-31T02:26:14.756312Z"
    }
   },
   "source": [
    "# Load a pre-trained zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:21.974961Z",
     "start_time": "2024-05-31T02:26:19.732454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the query and candidate labels\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used in state S, rather than action B?\"]\n",
    "query = \"What made 'push box to the left' more suitable than 'move to the right'?\"\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(query, candidate_labels)\n",
    "pprint(result, width=100)"
   ],
   "id": "11ca92d38e459308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Why is action A used in the plan?',\n",
      "            'Why is action A not used in the plan?',\n",
      "            'Why is action A used in state S, rather than action B?'],\n",
      " 'scores': [0.3973885476589203, 0.3694774806499481, 0.2331339716911316],\n",
      " 'sequence': \"What made 'push box to the left' more suitable than 'move to the right'?\"}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:23.696771Z",
     "start_time": "2024-05-31T02:26:21.975858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the query and candidate labels\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used rather than action B?\"]\n",
    "query = \"What made 'push box to the left' more suitable than 'move to the right'?\"\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(query, candidate_labels)\n",
    "pprint(result, width=100)"
   ],
   "id": "7c4f14fc6d35d73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Why is action A used rather than action B?',\n",
      "            'Why is action A used in the plan?',\n",
      "            'Why is action A not used in the plan?'],\n",
      " 'scores': [0.7602096199989319, 0.12425892055034637, 0.11553144454956055],\n",
      " 'sequence': \"What made 'push box to the left' more suitable than 'move to the right'?\"}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It seems that \"Why is action A used rather than action B?\" is a better intent category label than \"Why is action A used in state S, rather than action B?\".",
   "id": "792b0f39e6f149da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<br>",
   "id": "e4973a09e9b1342d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Multiple Text Prediction and Evaluation\n",
    "Predict the intents of the sentences in the text column from the data csv, compare them with the actual labels, and print the evaluation metrics."
   ],
   "id": "9da3c2e820168eb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:29:47.797756Z",
     "start_time": "2024-05-31T02:29:47.791032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('./data/intent_classification_dataset.csv')\n",
    "print(f\"Number of rows in the dataset: {df.shape[0]}\")\n",
    "df.head()"
   ],
   "id": "eeeacfb419714fb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  Why is action A not included in the project ro...      1\n",
       "1  What are the reasons for excluding action A fr...      1\n",
       "2        Why was action A omitted from the strategy?      1\n",
       "3  Why didn't we consider action A for the projec...      1\n",
       "4       Why was action A left out of the final plan?      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is action A not included in the project ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the reasons for excluding action A fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why was action A omitted from the strategy?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why didn't we consider action A for the projec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was action A left out of the final plan?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:24.205129Z",
     "start_time": "2024-05-31T02:26:24.202533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the candidate labels and their corresponding intent numbers\n",
    "candidate_labels = [\"Why is action A not used in the plan?\", \n",
    "                    \"Why is action A used in the plan?\", \n",
    "                    \"Why is action A used rather than action B?\"]\n",
    "\n",
    "intent_to_label = {label: intent for label, intent in zip(candidate_labels, range(1, 4))}\n",
    "intent_to_label"
   ],
   "id": "e4aea201d3bdc9ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Why is action A not used in the plan?': 1,\n",
       " 'Why is action A used in the plan?': 2,\n",
       " 'Why is action A used rather than action B?': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:26:27.553122Z",
     "start_time": "2024-05-31T02:26:24.205708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load a pre-trained zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Function to get predictions for each text\n",
    "def get_prediction(text):\n",
    "    result = classifier(text, candidate_labels)\n",
    "    predicted_label = intent_to_label[result['labels'][0]]\n",
    "    return predicted_label"
   ],
   "id": "70fc8d178444a138",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:29:47.767834Z",
     "start_time": "2024-05-31T02:26:27.554217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to the text column\n",
    "df['predicted_label'] = df['text'].apply(get_prediction)"
   ],
   "id": "9a858916c12682b1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:29:47.782325Z",
     "start_time": "2024-05-31T02:29:47.769639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare predicted labels with actual labels\n",
    "y_true = df['label']\n",
    "y_pred = df['predicted_label']\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")"
   ],
   "id": "a5c48f13821b6de4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.99        36\n",
      "           2       0.97      1.00      0.99        35\n",
      "           3       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           0.99       107\n",
      "   macro avg       0.99      0.99      0.99       107\n",
      "weighted avg       0.99      0.99      0.99       107\n",
      "\n",
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T02:29:47.788760Z",
     "start_time": "2024-05-31T02:29:47.783081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the rows in which the predictions didn't match the label\n",
    "incorrect_predictions = df[df['label'] != df['predicted_label']]\n",
    "incorrect_predictions"
   ],
   "id": "51ca88d65c800c3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "35  The player doesn't push any boxes. Shouldn't p...      1                2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The player doesn't push any boxes. Shouldn't p...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
